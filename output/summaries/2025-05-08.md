# 📰 Hugging Face Daily Papers – 2025-05-08

## 2505.04588
🔗 https://huggingface.co/papers/2505.04588

**Summary**:
해당 논문은 대형 언어 모델(LLM)의 검색 능력을 향상시키기 위한 새로운 강화 학습 프레임워크인 **ZeroSearch**를 제안합니다. 이 방법은 실제 검색 엔진과의 상호작용 없이도 LLM의 검색 기능을 효과적으로 개선할 수 있습니다.

**1. 핵심 동기와 문제 정의**

대형 언어 모델의 추론 및 생성 능력을 향상시키기 위해서는 효과적인 정보 검색이 필수적입니다. 그러나 기존의 강화 학습 기반 접근법은 검색 엔진과의 상호작용으로 인한 문서 품질의 불안정성과 높은 API 비용 등의 문제에 직면해 있습니다.

**2. 주요 기여 및 참신성**

- **ZeroSearch 프레임워크 제안**: 실제 검색 엔진과의 상호작용 없이 LLM의 검색 능력을 향상시키는 새로운 강화 학습 프레임워크를 소개합니다.
- **경량화된 지도 학습 미세 조정**: LLM을 검색 모듈로 변환하기 위해 경량화된 지도 학습 미세 조정 기법을 적용합니다.
- **점진적 롤아웃 전략**: 훈련 과정에서 문서 품질을 점진적으로 저하시켜 모델의 추론 능력을 단계적으로 향상시킵니다.
- **다양한 모델 및 알고리즘에 대한 일반화**: ZeroSearch는 다양한 크기의 기본 및 지시 조정된 모델에 대해 잘 일반화되며, 여러 강화 학습 알고리즘과 호환됩니다.

**3. 모델 아키텍처 및 학습 설정**

- **모델 아키텍처**: 3B, 7B, 14B 파라미터를 가진 LLM을 검색 모듈로 활용합니다.
- **학습 설정**: 경량화된 지도 학습 미세 조정 후, 점진적 롤아웃 전략을 통해 강화 학습을 수행합니다.

**4. 실험 설정**

- **사용된 데이터셋**: 구체적인 데이터셋 정보는 제공되지 않았습니다.
- **마스킹 방식**: 훈련 과정에서 문서 품질을 점진적으로 저하시켜 모델의 추론 능력을 향상시킵니다.
- **비교 대상(Baseline)**: 실제 검색 엔진과의 상호작용을 통해 얻은 결과와 비교합니다.

**5. 정량적 결과**

- **성능 비교**: 3B 파라미터 모델을 검색 모듈로 활용한 ZeroSearch는 실제 검색 엔진과 유사한 성능을 보였습니다. 7B 모델은 이를 능가하며, 14B 모델은 더욱 우수한 성능을 달성했습니다.

**6. 한계점 및 잠재적 실패 요인**

- **데이터셋 의존성**: 구체적인 데이터셋 정보가 제공되지 않아, 특정 도메인이나 데이터셋에 대한 성능을 평가하기 어렵습니다.
- **모델 크기 의존성**: 모델 크기에 따라 성능이 달라질 수 있으며, 작은 모델에서는 성능이 저하될 가능성이 있습니다.

**7. 후속 연구 아이디어 또는 확장 방향**

- **다양한 도메인 적용**: ZeroSearch를 다양한 도메인과 데이터셋에 적용하여 일반화 성능을 평가합니다.
- **모델 최적화**: 더 작은 모델에서도 우수한 성능을 낼 수 있도록 모델 구조와 학습 방법을 최적화합니다.
- **실제 검색 엔진과의 통합**: ZeroSearch를 실제 검색 엔진과 통합하여 실용적인 검색 시스템을 개발합니다. 

---

## 2505.04364
🔗 https://huggingface.co/papers/2505.04364

**Summary**:
해당 논문은 대형 언어 모델(LLMs)이 제한된 지역 인식과 통신을 가진 다중 에이전트 시스템(MAS)에서의 분산 조정 능력을 평가하기 위해 새로운 벤치마크인 SwarmBench를 제안합니다. 이 벤치마크는 2D 그리드 환경에서 에이전트들이 지역 감각 입력과 지역 통신에 의존하여 협력하는 다섯 가지 기본적인 MAS 조정 작업을 포함하고 있습니다. 이를 통해 LLMs의 분산 조정 능력과 emergent group dynamics를 분석하고, 미래의 분산 시스템에서 LLMs의 잠재력을 실현하기 위한 평가 도구로 활용될 수 있습니다. 

---

