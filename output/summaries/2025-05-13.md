# 📰 Hugging Face Daily Papers – 2025-05-13

## 2505.07062
🔗 https://huggingface.co/papers/2505.07062

**Summary**:
```markdown
# Seed1.5-VL 기술 보고서 요약

## 1. 핵심 동기와 문제 정의

Seed1.5-VL은 일반 목적의 멀티모달 이해와 추론을 향상시키기 위해 설계된 비전-언어 기초 모델입니다. 이 모델은 다양한 공개 벤치마크에서 우수한 성능을 달성하며, 특히 60개의 공개 벤치마크 중 38개에서 최첨단 성능을 보입니다. 

## 2. 주요 기여 및 참신성

- **효율적인 모델 아키텍처**: 532M 파라미터의 비전 인코더와 20B 활성 파라미터를 가진 혼합 전문가(MoE) 기반의 대형 언어 모델을 결합하여, 상대적으로 작은 크기에도 불구하고 강력한 성능을 발휘합니다.

- **우수한 멀티모달 성능**: 38개의 공개 벤치마크에서 최첨단 성능을 달성하며, 특히 GUI 제어 및 게임 플레이와 같은 에이전트 중심 작업에서 OpenAI CUA 및 Claude 3.7을 능가합니다.

- **강력한 추론 능력**: 시각적 퍼즐과 같은 멀티모달 추론 과제에서 뛰어난 성능을 보입니다.

## 3. 모델 아키텍처 및 학습 설정

- **비전 인코더**: 532M 파라미터를 가진 비전 인코더를 사용하여 시각적 정보를 효과적으로 처리합니다.

- **언어 모델**: 20B 활성 파라미터를 가진 혼합 전문가(MoE) 기반의 대형 언어 모델을 채택하여, 다양한 언어적 패턴과 지식을 학습합니다.

- **학습 설정**: 대규모 멀티모달 데이터셋을 활용하여 모델을 학습하며, 다양한 벤치마크에서 평가하여 성능을 검증합니다.

## 4. 실험 설정

- **사용된 데이터셋**: 공개된 멀티모달 벤치마크와 내부 평가 스위트를 활용하여 모델의 성능을 평가합니다.

- **마스킹 방식**: 구체적인 마스킹 방식에 대한 상세 정보는 제공되지 않았습니다.

- **비교 대상(Baseline)**: OpenAI CUA 및 Claude 3.7과 같은 기존 멀티모달 시스템과 비교하여 성능을 평가합니다.

## 5. 정량적 결과

Seed1.5-VL은 60개의 공개 벤치마크 중 38개에서 최첨단 성능을 달성하였으며, 특히 GUI 제어 및 게임 플레이와 같은 에이전트 중심 작업에서 기존의 멀티모달 시스템을 능가하는 성능을 보였습니다. 

## 6. 한계점 및 잠재적 실패 요인

- **모델 크기와 효율성**: 상대적으로 작은 모델 크기에도 불구하고 우수한 성능을 보이지만, 특정 복잡한 작업에서는 성능이 제한될 수 있습니다.

- **데이터셋의 다양성**: 사용된 데이터셋의 다양성이 제한적일 경우, 모델의 일반화 능력이 저하될 수 있습니다.

## 7. 후속 연구 아이디어 또는 확장 방향

- **모델 크기 확장**: 더 큰 모델을 통해 성능을 향상시킬 수 있으며, 특히 복잡한 멀티모달 작업에서의 성능 개선이 기대됩니다.

- **데이터셋 다양성 증가**: 더 다양한 데이터셋을 활용하여 모델의 일반화 능력을 향상시킬 수 있습니다.

- **추론 능력 강화**: 더 복잡한 추론 과제를 처리할 수 있도록 모델의 추론 능력을 강화하는 연구가 필요합니다.
```
 

---

## 2505.07608
🔗 https://huggingface.co/papers/2505.07608

**Summary**:
```markdown
# MiMo: 언어 모델의 추론 잠재력 발현 - 사전 학습에서 후속 학습까지

## 1. 핵심 동기와 문제 정의

대형 언어 모델의 추론 능력을 향상시키기 위해, 사전 학습과 후속 학습 단계에서 최적화를 수행하는 새로운 접근법이 필요합니다.

## 2. 주요 기여 및 참신성

- **사전 학습 최적화**: 데이터 전처리 파이프라인 개선 및 세 단계 데이터 혼합 전략을 통해 모델의 추론 잠재력 강화.
- **다중 토큰 예측 목표 도입**: 성능 향상과 추론 속도 가속화를 위한 새로운 학습 목표 설정.
- **후속 학습 최적화**: 13만 개의 검증 가능한 수학 및 프로그래밍 문제로 강화 학습 데이터셋 구성.
- **테스트 난이도 기반 보상 체계 도입**: 희소 보상 문제 완화를 위한 새로운 보상 메커니즘 적용.
- **전략적 데이터 재샘플링 기법 적용**: 학습 안정성을 높이기 위한 데이터 샘플링 전략 도입.

## 3. 모델 아키텍처 및 학습 설정

- **사전 학습**:
  - **데이터 전처리 개선**: 모델의 추론 능력 강화를 위한 데이터 전처리 파이프라인 최적화.
  - **세 단계 데이터 혼합 전략**: 다양한 데이터 소스를 결합하여 모델의 일반화 능력 향상.
  - **다중 토큰 예측 목표**: 모델의 성능과 추론 속도 향상을 위한 새로운 학습 목표 설정.
- **후속 학습**:
  - **강화 학습 데이터셋 구성**: 13만 개의 검증 가능한 수학 및 프로그래밍 문제로 데이터셋 구성.
  - **테스트 난이도 기반 보상 체계**: 모델의 학습을 유도하기 위한 새로운 보상 메커니즘 적용.
  - **전략적 데이터 재샘플링**: 학습 안정성을 높이기 위한 데이터 샘플링 기법 도입.

## 4. 실험 설정

- **사용된 데이터셋**: 13만 개의 검증 가능한 수학 및 프로그래밍 문제로 구성된 데이터셋.
- **마스킹 방식**: 구체적인 마스킹 방식에 대한 정보는 제공되지 않음.
- **비교 대상(Baseline)**: OpenAI의 o1-mini 모델과 비교하여 성능 평가.

## 5. 정량적 결과

- **사전 학습 모델(MiMo-7B-Base)**: 25조 개의 토큰으로 사전 학습된 모델로, 32B 모델보다 우수한 추론 잠재력을 보임.
- **후속 학습 모델(MiMo-7B-RL)**: 수학, 코드, 일반 추론 작업에서 OpenAI o1-mini 모델을 능가하는 성능을 달성.

## 6. 한계점 및 잠재적 실패 요인

- **데이터셋의 다양성 부족**: 특정 분야에 집중된 데이터셋으로 인해 모델의 일반화 능력이 제한될 수 있음.
- **보상 체계의 복잡성**: 테스트 난이도 기반 보상 체계가 모델 학습에 예상치 못한 영향을 미칠 가능성 있음.
- **전략적 데이터 재샘플링의 효과성**: 데이터 재샘플링 기법이 모든 상황에서 학습 안정성을 높이지 않을 수 있음.

## 7. 후속 연구 아이디어 또는 확장 방향

- **데이터셋 다양성 확대**: 다양한 분야의 문제를 포함한 데이터셋을 구축하여 모델의 일반화 능력 향상.
- **보상 체계 개선**: 모델 학습에 미치는 영향을 최소화하기 위한 보상 체계의 최적화.
- **데이터 재샘플링 기법의 최적화**: 다양한 상황에서 효과적인 데이터 재샘플링 전략 개발.
```
 

---

## 2505.07787
🔗 https://huggingface.co/papers/2505.07787

**Summary**:
```markdown
# 논문 요약: "Learning from Peers in Reasoning Models"

## 1. 핵심 동기와 문제 정의

대형 추론 모델(Large Reasoning Models, LRM)은 추론 경로에서 실수를 스스로 수정할 수 있는 능력을 지니고 있으나, 부정확한 시작점에서 출발할 경우 회복이 어려운 "접두사 지배 함정(Prefix Dominance Trap)" 현상이 존재합니다.

## 2. 주요 기여 및 참신성

- **동료 학습(LeaP) 제안**: 각 추론 경로가 중간 추론 결과를 요약하여 다른 경로와 공유함으로써 상호 학습을 촉진하는 메커니즘을 도입하였습니다.
- **LeaP-T 모델 시리즈 개발**: 소형 모델이 효과적으로 동료 학습을 수행할 수 있도록 세부 조정된 모델 시리즈를 제시하였습니다.
- **다양한 벤치마크에서의 성능 향상**: AIME 2024, AIME 2025, AIMO 2025, GPQA Diamond 등에서 LeaP를 적용한 모델이 기존 모델 대비 유의미한 성능 향상을 보였습니다.

## 3. 모델 아키텍처 및 학습 설정

- **동료 학습 메커니즘**: 각 추론 경로는 중간 결과를 요약하여 다른 경로와 공유하며, 이를 통해 상호 학습을 수행합니다.
- **LeaP-T 모델 시리즈**: 소형 모델이 동료 학습을 효과적으로 수행할 수 있도록 세부 조정된 모델 시리즈로, 기존 모델의 한계를 극복합니다.

## 4. 실험 설정

- **사용된 데이터셋**: AIME 2024, AIME 2025, AIMO 2025, GPQA Diamond 등 다양한 벤치마크 데이터셋을 활용하였습니다.
- **마스킹 방식**: 구체적인 마스킹 방식에 대한 상세 정보는 제공되지 않았습니다.
- **비교 대상(Baseline)**: 기존의 DeepSeek-R1-671B 모델과 DeepSeek-R1-Distill-Qwen-14B 모델을 주요 비교 대상으로 설정하였습니다.

## 5. 정량적 결과

- **성능 향상**: QwQ-32B 모델에 LeaP를 적용한 결과, 기존 모델 대비 평균 5점의 성능 향상을 달성하였습니다.
- **벤치마크 비교**: DeepSeek-R1-671B 모델을 능가하며, AIME 2024에서 LeaP-T-7B 모델이 DeepSeek-R1-Distill-Qwen-14B 모델과 동등한 성능을 보였습니다.

## 6. 한계점 및 잠재적 실패 요인

- **소형 모델의 동료 학습 수행 한계**: 일부 소형 모델은 동료 학습을 효과적으로 수행하지 못하는 경우가 발생할 수 있습니다.
- **추론 경로의 다양성 부족**: 동료 학습 메커니즘이 모든 유형의 추론 경로에 대해 효과적이지 않을 수 있습니다.

## 7. 후속 연구 아이디어 또는 확장 방향

- **동료 학습 메커니즘의 최적화**: 소형 모델이 동료 학습을 효과적으로 수행할 수 있도록 메커니즘을 개선하는 연구가 필요합니다.
- **추론 경로 다양성 증대**: 다양한 유형의 추론 경로에 대해 동료 학습이 효과적으로 작동하도록 경로 다양성을 증대시키는 방법을 모색해야 합니다.
```
 

---

## 2505.03733
🔗 https://huggingface.co/papers/2505.03733

**Summary**:
```markdown
# WebGen-Bench: 제로부터 상호작용 가능한 기능성 웹사이트 생성 평가

## 1. 핵심 동기와 문제 정의

대형 언어 모델(LLM) 기반 에이전트는 복잡한 코드베이스 내에서 코드 생성 및 관리에 큰 잠재력을 보입니다. 본 연구에서는 LLM 기반 에이전트가 제로부터 다중 파일로 구성된 웹사이트 코드베이스를 생성하는 능력을 평가하기 위한 새로운 벤치마크인 WebGen-Bench를 소개합니다.

## 2. 주요 기여 및 참신성

- **WebGen-Bench 개발**: 다양한 웹사이트 생성 지침을 포함하는 새로운 벤치마크를 구축하여 LLM 기반 에이전트의 성능을 평가합니다.
- **다양한 지침 생성**: 인간 주석자와 GPT-4o의 협업을 통해 세 가지 주요 범주와 열세 가지 하위 범주에 걸쳐 다양한 웹 애플리케이션 유형을 포괄하는 지침을 생성합니다.
- **테스트 케이스 설계 및 자동화**: 각 기능에 대한 테스트 케이스를 생성하고, 이를 자동화된 웹 탐색 에이전트를 통해 실행하여 결과의 정확성을 평가합니다.
- **성능 평가 및 모델 훈련**: 세 가지 고성능 코드 에이전트 프레임워크와 여러 LLM을 사용하여 성능을 평가하고, Qwen2.5-Coder-32B-Instruct 모델을 훈련하여 기존 모델을 능가하는 성능을 달성합니다.

## 3. 모델 아키텍처 및 학습 설정

- **코드 에이전트 프레임워크**: Bolt.diy, OpenHands, Aider의 세 가지 프레임워크를 평가합니다.
- **LLM 엔진**: 여러 상용 및 오픈 소스 LLM을 엔진으로 사용하여 성능을 비교합니다.
- **훈련 데이터셋**: 6,667개의 웹사이트 생성 지침을 포함하는 WebGen-Instruct 데이터셋을 구축하여 모델 훈련에 활용합니다.
- **훈련 설정**: Bolt.diy 프레임워크에서 Qwen2.5-Coder-32B-Instruct 모델을 훈련하여 성능을 향상시킵니다.

## 4. 실험 설정

- **사용된 데이터셋**: WebGen-Bench 벤치마크와 WebGen-Instruct 훈련 데이터셋을 사용합니다.
- **마스킹 방식**: 각 기능에 대한 테스트 케이스를 생성하고, 이를 자동화된 웹 탐색 에이전트를 통해 실행하여 결과의 정확성을 평가합니다.
- **비교 대상(Baseline)**: Bolt.diy, OpenHands, Aider의 세 가지 코드 에이전트 프레임워크와 여러 LLM을 비교 대상으로 사용합니다.

## 5. 정량적 결과

- **성능 비교**: Bolt.diy 프레임워크와 DeepSeek-R1 LLM 조합은 27.8%의 정확도를 달성하였으며, Qwen2.5-Coder-32B-Instruct 모델은 38.2%의 정확도로 기존 모델을 능가합니다.

## 6. 한계점 및 잠재적 실패 요인

- **복잡한 웹사이트 생성의 어려움**: 다양한 기능과 복잡한 구조를 가진 웹사이트를 제로부터 생성하는 것은 현재 기술로는 도전적인 과제입니다.
- **테스트 케이스의 다양성**: 다양한 웹 애플리케이션 유형을 포괄하는 테스트 케이스의 설계와 실행이 어려울 수 있습니다.

## 7. 후속 연구 아이디어 또는 확장 방향

- **모델 성능 향상**: 더 큰 규모의 LLM과 고급 코드 에이전트 프레임워크를 활용하여 성능을 향상시킬 수 있습니다.
- **데이터셋 확장**: 더 다양한 웹 애플리케이션 유형과 기능을 포함하는 데이터셋을 구축하여 모델의 일반화 능력을 향상시킬 수 있습니다.
- **자동화된 테스트 개선**: 테스트 케이스의 다양성과 복잡성을 증가시켜 모델의 실제 웹사이트 생성 능력을 더욱 정확하게 평가할 수 있습니다.
```
 

---

## 2505.06548
🔗 https://huggingface.co/papers/2505.06548

**Summary**:
해당 논문은 "REFINE-AF: 자동화된 피드백을 통한 자기 생성 지침을 활용한 언어 모델 정렬을 위한 작업 비의존적 프레임워크"로, 대형 언어 모델(LLM)의 지침 기반 학습을 위한 효율적인 방법을 제시합니다.

**1. 핵심 동기와 문제 정의**

대형 언어 모델의 지침 기반 학습은 소량의 데이터로도 우수한 성능을 보이지만, 인간 주석 데이터 생성이 시간과 비용이 많이 들며, 데이터의 양과 다양성이 제한적입니다.

**2. 주요 기여 및 참신성**

- **작업 비의존적 지침 생성**: 모델 자체에서 지침을 반자동으로 생성하여 인간의 개입을 최소화합니다.
- **소형 오픈소스 LLM 활용**: GPT-3.5와 같은 대형 모델 대신 LLaMA 2-7B, LLaMA 2-13B, Mistral 7B와 같은 소형 오픈소스 모델을 사용합니다.
- **강화 학습 기반 학습 알고리즘 도입**: 자동화된 피드백을 활용한 강화 학습을 통해 모델 성능을 향상시킵니다.

**3. 모델 아키텍처 및 학습 설정**

- **모델 아키텍처**: LLaMA 2-7B, LLaMA 2-13B, Mistral 7B와 같은 소형 오픈소스 LLM을 기반으로 합니다.
- **학습 설정**: 반자동 지침 생성 프레임워크를 통해 인간의 개입을 최소화하며, 강화 학습 알고리즘을 적용하여 모델을 학습합니다.

**4. 실험 설정**

- **사용된 데이터셋**: 자세한 데이터셋 정보는 제공되지 않았습니다.
- **마스킹 방식**: 구체적인 마스킹 방식에 대한 정보는 제공되지 않았습니다.
- **비교 대상(Baseline)**: 이전의 지침 생성 방법들과 비교하여 성능을 평가합니다.

**5. 정량적 결과**

강화 학습 기반 프레임워크는 이전 방법들에 비해 63-66%의 작업에서 성능 향상을 달성하였습니다.

**6. 한계점 및 잠재적 실패 요인**

- **데이터셋 및 마스킹 방식의 상세 정보 부족**: 실험 설정에 대한 구체적인 정보가 부족하여 재현성에 대한 우려가 있을 수 있습니다.
- **소형 모델의 한계**: 소형 모델은 대형 모델에 비해 성능이 제한적일 수 있습니다.

**7. 후속 연구 아이디어 또는 확장 방향**

- **대형 모델 적용**: GPT-3.5와 같은 대형 모델을 활용하여 성능 향상을 시도할 수 있습니다.
- **다양한 데이터셋 적용**: 다양한 데이터셋을 활용하여 모델의 일반화 능력을 평가할 수 있습니다.
- **마스킹 방식 개선**: 마스킹 방식을 최적화하여 모델의 학습 효율성을 높일 수 있습니다. 

---

## 2505.07818
🔗 https://huggingface.co/papers/2505.07818

**Summary**:
```markdown
# DanceGRPO: 시각 생성에 대한 GRPO의 활용

## 1. 핵심 동기와 문제 정의

최근 생성 모델, 특히 확산 모델과 정류 흐름 모델의 발전은 시각 콘텐츠 생성에 혁신을 가져왔지만, 모델 출력이 인간의 선호와 일치하도록 조정하는 데에는 여전히 큰 도전이 존재합니다. 기존의 강화 학습 기반 시각 생성 방법들은 현대의 상미분방정식(ODE) 기반 샘플링 패러다임과의 비호환성, 대규모 학습의 불안정성, 그리고 비디오 생성에 대한 검증 부족 등의 문제를 안고 있습니다.

## 2. 주요 기여 및 참신성

- **통합된 강화 학습 프레임워크 제안**: Group Relative Policy Optimization(GRPO)을 시각 생성 패러다임에 적용한 최초의 통합된 프레임워크인 DanceGRPO를 소개합니다.

- **다양한 생성 패러다임에 대한 적용**: 확산 모델과 정류 흐름 모델 등 두 가지 생성 패러다임에 대해 하나의 통합된 강화 학습 알고리즘을 적용합니다.

- **다양한 작업에 대한 적용**: 텍스트-이미지, 텍스트-비디오, 이미지-비디오 등 세 가지 작업에 대해 적용 가능합니다.

- **다양한 기초 모델에 대한 적용**: Stable Diffusion, HunyuanVideo, FLUX, SkyReel-I2V 등 네 가지 기초 모델에 대해 적용합니다.

- **다양한 보상 모델에 대한 적용**: 이미지/비디오 미학, 텍스트-이미지 정렬, 비디오 모션 품질, 이진 보상 등 다섯 가지 보상 모델에 대해 적용 가능합니다.

- **성능 향상**: HPS-v2.1, CLIP Score, VideoAlign, GenEval 등의 벤치마크에서 기존 방법들보다 최대 181% 향상된 성능을 달성합니다.

## 3. 모델 아키텍처 및 학습 설정

DanceGRPO는 GRPO를 기반으로 한 강화 학습 알고리즘으로, 다양한 생성 패러다임과 작업에 대해 통합된 학습을 수행합니다. 이 모델은 기초 모델과 보상 모델을 결합하여 시각 생성의 품질을 향상시키는 것을 목표로 합니다.

## 4. 실험 설정

- **사용된 데이터셋**: HPS-v2.1, CLIP Score, VideoAlign, GenEval 등의 벤치마크 데이터셋을 사용하여 모델의 성능을 평가합니다.

- **마스킹 방식**: 논문에서 구체적인 마스킹 방식에 대한 언급은 없으나, 일반적으로 생성 모델에서는 입력 데이터의 일부를 마스킹하여 모델의 생성 능력을 평가합니다.

- **비교 대상(Baseline)**: 기존의 강화 학습 기반 시각 생성 방법들과 비교하여 성능을 평가합니다.

## 5. 정량적 결과

DanceGRPO는 HPS-v2.1, CLIP Score, VideoAlign, GenEval 등의 벤치마크에서 기존 방법들보다 최대 181% 향상된 성능을 달성하였습니다. 이러한 결과는 DanceGRPO가 다양한 생성 패러다임과 작업에 대해 효과적으로 적용될 수 있음을 보여줍니다.

## 6. 한계점 및 잠재적 실패 요인

논문에서는 DanceGRPO의 한계점이나 잠재적 실패 요인에 대한 구체적인 언급이 없습니다. 그러나 일반적으로 강화 학습 기반 생성 모델은 학습의 안정성, 샘플링의 다양성, 그리고 계산 자원의 요구 사항 등에서 도전 과제를 가질 수 있습니다.

## 7. 후속 연구 아이디어 또는 확장 방향

- **다양한 보상 모델의 탐색**: 다양한 보상 모델을 실험하여 모델의 성능을 더욱 향상시킬 수 있습니다.

- **다양한 생성 패러다임에 대한 적용**: 다른 생성 모델이나 작업에 대해 DanceGRPO를 적용하여 그 범위를 확장할 수 있습니다.

- **학습 안정성 향상**: 강화 학습의 안정성을 높이기 위한 새로운 기법이나 알고리즘을 개발할 수 있습니다.

- **실제 응용 분야로의 확장**: DanceGRPO를 실제 응용 분야에 적용하여 그 유용성을 검증할 수 있습니다.
```
 

---

## 2505.07796
🔗 https://huggingface.co/papers/2505.07796

**Summary**:
해당 논문은 "대형 언어 모델의 지속적 사전 학습에서의 학습 동역학"을 다루고 있습니다. 이 연구는 지속적 사전 학습(CPT) 과정에서의 학습 동역학을 탐구하며, 특히 각 훈련 단계에서 일반 도메인과 다운스트림 도메인 성능의 변화를 분석합니다. 또한, 분포 변화와 학습률 조절의 영향을 분리하여 CPT 손실 곡선을 설명하고, 이를 통해 CPT 스케일링 법칙을 도출합니다. 이 법칙은 다양한 CPT 데이터셋과 훈련 하이퍼파라미터에 걸쳐 손실을 예측하는 데 활용됩니다.

**핵심 동기와 문제 정의**

- 대형 언어 모델의 지속적 사전 학습(CPT) 과정에서의 학습 동역학을 이해하고, 일반 도메인과 다운스트림 도메인 성능의 변화를 분석하는 것이 주요 목표입니다.

**주요 기여 및 참신성**

- CPT 손실 곡선이 분포 변화와 학습률 조절의 영향을 분리하여 설명할 수 있음을 발견하였습니다.
- CPT 스케일링 법칙을 도출하여, 다양한 훈련 단계와 학습률 스케줄에 걸쳐 손실을 예측할 수 있게 하였습니다.
- 손실 잠재력, 최고 학습률, 훈련 단계, 리플레이 비율 등 CPT의 여러 중요한 요소를 포괄적으로 이해할 수 있는 틀을 제시하였습니다.
- 이 접근법을 통해 일반 도메인과 도메인 특화 성능의 균형을 맞추는 등 다양한 CPT 목표에 맞게 훈련 하이퍼파라미터를 조정할 수 있습니다.

**모델 아키텍처 및 학습 설정**

- 대형 언어 모델을 대상으로 지속적 사전 학습(CPT)을 수행하였으며, 훈련 과정에서의 손실 곡선과 성능 변화를 분석하였습니다.
- 분포 변화와 학습률 조절의 영향을 분리하여 CPT 손실 곡선을 설명하였습니다.
- CPT 스케일링 법칙을 도출하여, 다양한 훈련 단계와 학습률 스케줄에 걸쳐 손실을 예측할 수 있게 하였습니다.

**실험 설정**

- **사용된 데이터셋**: 다양한 CPT 데이터셋을 활용하여 실험을 진행하였습니다.
- **마스킹 방식**: 구체적인 마스킹 방식에 대한 정보는 제공되지 않았습니다.
- **비교 대상(Baseline)**: 기존의 지속적 사전 학습 방법들과 비교하여 성능을 평가하였습니다.

**정량적 결과**

- CPT 스케일링 법칙이 다양한 CPT 데이터셋과 훈련 하이퍼파라미터에 걸쳐 손실을 예측하는 데 효과적임을 확인하였습니다.
- 이러한 결과는 기존의 지속적 사전 학습 방법들과 비교하여 우수한 성능을 보였습니다.

**한계점 및 잠재적 실패 요인**

- 구체적인 한계점이나 잠재적 실패 요인에 대한 정보는 제공되지 않았습니다.

**후속 연구 아이디어 또는 확장 방향**

- CPT 스케일링 법칙을 다른 유형의 모델이나 데이터셋에 적용하여 일반화 가능성을 검증하는 연구가 필요합니다.
- CPT 과정에서의 분포 변화와 학습률 조절의 영향을 더욱 정교하게 모델링하여 성능 향상을 도모할 수 있습니다. 

---

## 2505.07596
🔗 https://huggingface.co/papers/2505.07596

**Summary**:
해당 논문은 "효율적인 적응형 검색 에이전트를 위한 강화된 내부-외부 지식 시너지 추론"을 다루고 있습니다. 이 연구는 대형 언어 모델(LLM)의 환각 현상을 줄이기 위해 검색 증강 생성(RAG) 전략을 활용하며, 강화 학습(RL)을 통해 LLM이 검색 에이전트로서의 기능을 수행하도록 합니다. 그러나 기존 방법들은 내부 지식을 충분히 활용하지 못하여 중복된 검색, 지식 충돌, 추론 지연 등의 문제를 야기합니다. 이러한 한계를 극복하기 위해, 본 연구는 내부 지식과 외부 검색 지식을 시너지 있게 통합하는 효율적이고 적응적인 검색 에이전트인 IKEA를 제안합니다.

**주요 기여 및 참신성:**

- **지식 경계 인식 보상 함수 도입:** 내부 지식의 한계를 인식하고, 내부 지식이 부족할 때만 외부 검색을 활용하도록 유도하는 보상 함수를 설계하였습니다.

- **지식 경계 인식 학습 데이터셋 구축:** 내부 지식과 외부 지식의 활용 시점을 학습할 수 있도록 특화된 데이터셋을 구성하였습니다.

- **내부-외부 지식 시너지 강화:** 강화 학습을 통해 내부 지식과 외부 지식을 효과적으로 통합하여 정확한 답변을 생성하고, 불필요한 검색을 최소화하며, 적절한 외부 검색을 장려하는 모델을 개발하였습니다.

**모델 아키텍처 및 학습 설정:**

- **모델 구조:** 내부 지식과 외부 지식을 통합하는 강화 학습 기반의 에이전트로, 지식 경계 인식 보상 함수와 학습 데이터셋을 활용하여 내부 지식의 활용과 외부 검색의 시점을 조절합니다.

- **학습 설정:** 강화 학습을 통해 모델이 내부 지식과 외부 지식의 활용을 최적화하도록 학습하며, 지식 경계 인식 보상 함수와 특화된 학습 데이터셋을 사용하여 모델의 성능을 향상시킵니다.

**실험 설정:**

- **사용된 데이터셋:** 여러 지식 추론 작업을 수행하기 위해 다양한 데이터셋을 활용하였습니다.

- **마스킹 방식:** 내부 지식의 활용과 외부 검색의 시점을 조절하기 위해 지식 경계 인식 보상 함수를 적용하였습니다.

- **비교 대상(Baseline):** 기존의 RAG 기반 모델들과 비교하여 IKEA의 성능을 평가하였습니다.

**정량적 결과:**

- **성능 비교:** 여러 지식 추론 작업에서 IKEA는 기존 방법들보다 우수한 성능을 보였으며, 불필요한 검색 횟수를 크게 줄였습니다.

- **일반화 능력:** 다양한 작업에서 IKEA는 강력한 일반화 능력을 보여주었습니다.

**한계점 및 잠재적 실패 요인:**

- **내부 지식의 한계:** 내부 지식이 충분하지 않은 경우, 외부 검색에 의존하게 되어 성능이 저하될 수 있습니다.

- **보상 함수의 설계:** 지식 경계 인식 보상 함수의 설계가 부적절할 경우, 모델의 학습이 비효율적이거나 부정확할 수 있습니다.

**후속 연구 아이디어 또는 확장 방향:**

- **보상 함수의 개선:** 내부 지식과 외부 지식의 활용을 더욱 정교하게 조절할 수 있는 보상 함수의 설계를 연구할 수 있습니다.

- **다양한 도메인 적용:** 다양한 도메인에서 IKEA의 성능을 평가하고, 도메인 특성에 맞게 모델을 조정하는 연구가 필요합니다.

- **실시간 검색 최적화:** 실시간으로 변화하는 정보에 대응하기 위해, 실시간 검색 최적화 기법을 개발하는 것이 중요합니다. 

---

## 2505.07747
🔗 https://huggingface.co/papers/2505.07747

**Summary**:
```markdown
# Step1X-3D: 고해상도 및 제어 가능한 텍스처 3D 자산 생성

## 1. 핵심 동기와 문제 정의

텍스트, 이미지, 오디오, 비디오 분야에서 생성적 인공지능이 크게 발전했지만, 3D 생성은 데이터 부족, 알고리즘 한계, 생태계 단편화 등의 근본적인 문제로 인해 상대적으로 미비한 상태입니다. 

## 2. 주요 기여 및 참신성

- **엄격한 데이터 큐레이션 파이프라인 구축**: 5백만 개 이상의 자산을 처리하여 2백만 개의 고품질 데이터셋을 생성하고, 기하학적 및 텍스처적 속성을 표준화하였습니다.

- **2단계 3D 네이티브 아키텍처 제안**: 하이브리드 VAE-DiT 기하학 생성기와 확산 기반 텍스처 합성 모듈을 결합한 구조를 도입하였습니다.

- **모델, 학습 코드, 적응 모듈의 완전한 오픈 소스 공개**: 연구의 재현성과 확장성을 높였습니다.

- **2D 제어 기법의 3D 합성으로의 직접 전이 지원**: LoRA와 같은 2D 제어 기술을 3D 합성에 직접 적용할 수 있게 하여 2D와 3D 생성 패러다임 간의 격차를 해소하였습니다.

## 3. 모델 아키텍처 및 학습 설정

- **하이브리드 VAE-DiT 기하학 생성기**: Perceiver 기반 잠재 인코딩을 활용하여 세부 사항을 보존하는 선명한 엣지 샘플링을 통해 TSDF(Truncated Signed Distance Function) 표현을 생성합니다.

- **확산 기반 텍스처 합성 모듈**: 기하학적 조건화와 잠재 공간 동기화를 통해 시점 간 일관성을 유지합니다.

- **학습 설정**: 모델, 학습 코드, 적응 모듈을 완전하게 오픈 소스로 공개하여 연구의 재현성과 확장성을 높였습니다.

## 4. 실험 설정

- **사용된 데이터셋**: 5백만 개 이상의 자산을 처리하여 2백만 개의 고품질 데이터셋을 생성하였습니다.

- **마스킹 방식**: 기하학적 조건화와 잠재 공간 동기화를 통해 시점 간 일관성을 유지합니다.

- **비교 대상(Baseline)**: 기존의 오픈 소스 방법들과 비교하여 우수한 성능을 보였으며, 상용 솔루션과도 경쟁력 있는 품질을 달성하였습니다.

## 5. 정량적 결과

- **기존 방법들과의 성능 비교**: 벤치마크 결과, 기존의 오픈 소스 방법들을 능가하는 최첨단 성능을 달성하였으며, 상용 솔루션과도 경쟁력 있는 품질을 보였습니다.

## 6. 한계점 및 잠재적 실패 요인

- **데이터 품질 의존성**: 데이터 큐레이션의 품질이 모델 성능에 직접적인 영향을 미치므로, 데이터의 다양성과 품질 확보가 중요합니다.

- **계산 자원 요구 사항**: 고해상도 3D 자산 생성을 위한 계산 자원 소모가 크므로, 효율적인 자원 관리가 필요합니다.

## 7. 후속 연구 아이디어 또는 확장 방향

- **데이터 다양성 향상**: 다양한 분야와 스타일의 3D 자산을 포함하여 데이터셋의 다양성을 높이는 연구가 필요합니다.

- **효율성 개선**: 계산 자원 소모를 줄이기 위한 모델 최적화 및 경량화 연구가 요구됩니다.

- **응용 분야 확장**: 게임, 영화, 가상 현실 등 다양한 분야에서의 적용 가능성을 탐색하는 연구가 필요합니다.
```
 

---

