# scraper.py
import requests
from playwright.sync_api import sync_playwright

def fetch_paper_links(date="2025-05-05"):
    url = f"https://huggingface.co/papers/date/{date}"
    paper_links = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        print(f"ğŸ”— í˜ì´ì§€ ì—´ê¸°: {url}")
        page.goto(url, timeout=60000)

        try:
            # ë…¼ë¬¸ ë§í¬ê°€ ë“¤ì–´ ìˆëŠ” h3 > a[href^="/papers/"] ìš”ì†Œê°€ ë‚˜íƒ€ë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
            page.wait_for_selector('h3 > a[href^="/papers/"]', timeout=15000)
            links = page.query_selector_all('h3 > a[href^="/papers/"]')
            paper_links = ["https://huggingface.co" + link.get_attribute("href") for link in links]
        except Exception as e:
            print(f"â— ë…¼ë¬¸ ë§í¬ë¥¼ ì°¾ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            print(page.content()[:1000])  # ë Œë”ë§ëœ HTML ì¼ë¶€ ì¶œë ¥

        browser.close()

    return paper_links
